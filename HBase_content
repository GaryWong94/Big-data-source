HBase

---------------------------------------------------------------------------------------------------------------

Hbase是分布式、面向列的开源数据库（其实准确的说是面向列族）。

HDFS为Hbase提供可靠的底层数据存储服务，MapReduce为Hbase提供高性能的计算能力，Zookeeper为Hbase提供稳定服务和Failover机制。
因此我们说Hbase是一个通过大量廉价的机器解决海量数据的高速存储和读取的分布式数据库解决方案。
适合：巨量、查询简单、没有复杂关联 (海量订单流水、交易记录、数据库历史数据)

NoSQL产生原因：(1) 对于特定查询，不是所有值都必须，尤其OLAP中，因此可以减少IO
                 (2) 列的数据是类似的，便于压缩
                 (3) 数据越来越多，join之类的查询操作越来越慢，最后放弃辅助索引，只使用主键进行查询

五大特点：
  1.列式储存：
    这里的列式存储其实说的是列族存储，Hbase是根据列族来存储数据的。列族下面可以有非常多的列，列族在创建表的时候就必须指定。
    与RDBMS的对比：
      数据类型：字符串          丰富的数据
      数据操作：简单增删改查     丰富SQL
      存储模式：列存储          行存储
      

  2.海量储存 
    Hbase适合存储PB级别的海量数据，在PB级别的数据以及采用廉价PC存储的情况下，能在几十到百毫秒内返回数据。
    这与Hbase的极易扩展性息息相关。正式因为Hbase良好的扩展性，才为海量数据的存储提供了便利。

  3.易扩展 
    Hbase的扩展性主要体现在两个方面，一个是基于上层处理能力（RegionServer）的扩展，一个是基于存储的扩展（HDFS）。
    通过横向添加RegionSever的机器，进行水平扩展，提升Hbase上层的处理能力，提升Hbsae服务更多Region的能力。

    备注：RegionServer的作用是管理region、承接业务的访问，这个后面会详细的介绍通过横向添加Datanode的机器，进行存储层扩容，提升Hbase的数据存储能力和提升后端存储的读写能力。

  4.高并发 
  由于目前大部分使用Hbase的架构，都是采用的廉价PC，因此单个IO的延迟其实并不小，一般在几十到上百ms之间。
  这里说的高并发，主要是在并发的情况下，Hbase的单个IO延迟下降并不多。能获得高并发、低延迟的服务。

  5.稀疏
    稀疏主要是针对Hbase列的灵活性，在列族中，你可以指定任意多的列，在列数据为空的情况下，是不会占用存储空间的。

---------------------------------------------------------------------------------------------------------------

概念：
  1. column family：以列为单位聚合数据
        列族：列的家族，数量最好<=3
        
  2. Rowkey: Rowkey相当于mysql中的主键，Hbase使用Rowkey来唯一的区分某一行的数据。
      由于Hbase只支持3种查询方式：(1) 基于Rowkey的单行查询 (2) 基于Rowkey的范围扫描  (3) 全表扫描
      因此Rowkey设计很重要
      
  3. Region：相当于分区，将Rowkey按照范围划入不同的Region中，因此即使数据量很大，访问时延也很低
  
  4. TimeStamp: 实现HBase多版本，标识同一个Rowkey对应的不同版本的数据
      不指定会默认添加，相同Rowkey按照TimeStamp的倒序排列
      
  HBase架构如下：
    ![image](https://github.com/GaryWong94/Big-data-source/blob/master/pic/1506395765370_9254_1506395767893.png)

架构各部分解析：

- Client
    Client包含了访问Hbase的接口，另外Client还维护了对应的cache来加速Hbase的访问，比如cache的.META.元数据的信息。

- Zookeeper
    Hbase通过Zookeeper来做master的高可用、RegionServer的监控、元数据的入口以及集群配置的维护等工作。具体工作如下：
    通过Zoopkeeper来保证集群中只有1个master在运行，如果master异常，会通过竞争机制产生新的master提供服务
    通过Zoopkeeper来监控RegionServer的状态，当RegionSevrer有异常的时候，通过回调的形式通知Master RegionServer上下限的信息
    通过Zoopkeeper存储元数据的统一入口地址

- Hmaster   有点像namenode
    master节点的主要职责如下：
    为RegionServer分配Region
    维护整个集群的负载均衡
    维护集群的元数据信息
    发现失效的Region，并将失效的Region分配到正常的RegionServer上
    当RegionSever失效的时候，协调对应Hlog的拆分

- HregionServer     有点像worker node
    HregionServer直接对接用户的读写请求，是真正的“干活”的节点。它的功能概括如下：
      管理master为其分配的Region
      处理来自客户端的读写请求
      负责和底层HDFS的交互，存储数据到HDFS
      负责Region变大以后的拆分
      负责Storefile的合并工作

---------------------------------------------------------------------------------------------------------------

Region解析：
  Region寻址：需要读写一行数据，找哪个region
    第1步：Client请求ZK获取.META.所在的RegionServer的地址。
    第2步：Client请求.META.所在的RegionServer获取访问数据所在的RegionServer地址，client会将.META.的相关信息cache下来，以便下一次快速访问。
    第3步：Client请求数据所在的RegionServer，获取所需要的数据。
    
  Client中缓存的东西不更新，如果数据更新了，Client访问不到会报错，然后往上一级走，访问.META.在的RegionServer，还没有，再往上走，访问ZK

---------------------------------------------------------------------------------------------------------------

写入数据

第1步：Client获取数据写入的Region所在的RegionServer
第2步：请求写Hlog
第3步：请求写MemStore
只有当写Hlog和写MemStore都成功了才算请求写入完成。MemStore后续会逐渐刷到HDFS中。
备注：Hlog存储在HDFS，当RegionServer出现异常，需要使用Hlog来恢复数据。

---------------------------------------------------------------------------------------------------------------

MemStore刷盘




---------------------------------------------------------------------------------------------------------------




参考：
https://cloud.tencent.com/developer/article/1006043
https://cloud.tencent.com/developer/article/1006044
